# Glossary of MSE terms

This glossary is based off of [Rademeyer et al. (2007)](https://doi.org/10.1093/icesjms/fsm050) and [Punt et al. (2016)](https://doi.org/10.1111/faf.12104).

* **Assessment error** - Error that occurs during the process of conducting an assessment, specifically error "which inform the catch control rule that is being evaluated using the MSE: management advice for any system is based on uncertain data. Consequently, the data that inform catch control rules need to be generated in a manner which is as realistic as possible. Uncertainty arises when the model used for conducting assessments and providing management advice differs from the operating model, or the data are too noisy to estimate all key parameters reliably [(Punt et al. 2016)](https://doi.org/10.1111/faf.12104)."
* **Assessment model (AM)** - A fitted and well scrutinized Stock Synthesis stock assessment model. The AM is input for SSMSE so that it can build the operating model.
* **Bootstrapped dataset** - After running an SS3 model (and if the user turns on the option in the starter file), the output file data.ss_new contains a "dataset" that has the same form as the input data.ss file, but instead of the input values, contains a sampled dataset. This is derived from using the expected values given the parameter estimates and model structure (see glossary entry on **Expected values**), uncertainty either estimated or input in the model, and an assumed distribution for sampling. As many bootstrapped data sets as the user desires can be output from an SS3 model. These "bootstrap datasets" are the third or greater set of values in the data.ss_new file.
* **Estimation model (EM)** - This refers to the model used within the MSE procedure to represent the stock assessment process. Note that an estimation model proxy could also be used to represent the stock assessment process.
* **Expected values** - After running an SS3 model (and if the user turns on the option in the starter file), the output file data.ss_new contains a "dataset" that has the same form as the input data.ss file, but instead of the input values, contains the expected values given the parameter estimates and model structure. This "expected values dataset" is the second set of values in the data.ss_new file. 
* **Implementation error** - Also called implementation uncertainty or outcome uncertainty. Broadly, this includes error of implementing the management action(s), which is often not done perfectly. Definition from [Punt et al. (2016)](https://doi.org/10.1111/faf.12104): "The most obvious form of this type of uncertainty is when catches are
not the same as the TACs – typically more is taken or the decision-makers do not implement the TACs suggested by the management strategy. However, there are many other sources of outcome uncertainty, such as that associated with catch limits set for recreational fisheries and regulating discards."
* **Index** - An index of abundance. In SS3 files, this is sometimes used interchangably with CPUE. Plural, indices.
* **Management strategy** - Following [Punt et al. (2016)](https://doi.org/10.1111/faf.12104), there are 2 types: **model-based management strategies** and **empirical management strategies**. Ideally, SSMSE will allow for users to use either of these management strategies. Model-based management strategies include conducting a stock assessment and using output for determining harvest control rules. Empirical management strategies do not involve conducting a stock assessment but rather setting regulations from data (although summarization is possible). In some cases, management strategies are computationally intensive/time consuming to formally include in the context of an MSE; to speed up the process, it is commen to use **management strategy proxies**, typically an assumed error distribution about the operating model values. Management strategies are also known as management procedures.
* **Model uncertainty** - Definition from [Punt et al. (2016)](https://doi.org/10.1111/faf.12104): "the form of relationships within an operating model will always be subject to uncertainty. The simplest type of model uncertainty involves, for example, whether the stock–recruitment relationship is Beverton–Holt or Ricker, whether a fixed value for a model parameter is correct, or whether fishery selectivity is asymptotic or dome-shaped. However, there are other more complicated types of model structure uncertainty such as how many stocks are present in the area modelled, the error structure of the data used for assessment purposes, the impact of future climate change on biological relationships such as the stock–recruitment function, and ecosystem impacts on biological and fishery processes."
* **Observation error** - Error that results from not observing the true dynamics of the system. See also **bootstrapped dataset**.
* **Operating model (OM)** - This is an SS3 model that defines the assumed true dynamics of the population and its associated fisheries for the purposes of management strategy evaluation. Most often more than one operating model is necessary in order to adequately characterize the uncertainty in the true dynamics of the system. The SS3 OM may also define how sampling from the true dynamics is done, as SS3 produces expected values and, if desired, bootstrapped data sets based on sampling assumptions implicit in the model. For more information, see the glossary entries on **Expected values** and **bootstrapped dataset**
* **Parameter uncertainty** - Definition from [Punt et al. (2016)](https://doi.org/10.1111/faf.12104): "many operating models are fit to the data available, but the values estimated for the parameters of those operating models (e.g. fishery selectivity-at-age, the parameters of the stock–recruitment relationship and historical deviations in recruitment about the stock–recruitment relationship) are subject to error."
* **Performance statistics** - Definition from [Rademeyer et al. (2007)](https://doi.org/10.1093/icesjms/fsm050): "Statistics that summarize different aspects of the results of a simulation trial used to evaluate how well a specific [management strategy] achieves some or all of the general objectives for management for a particular scenario." Performance statistics usually fall into one of three categories: **catch-related**, **stability related**, or **risk related**.
* **Process uncertainty** - Definition from [Punt et al. (2016)](https://doi.org/10.1111/faf.12104): "variation (usually assumed to be random, though sometimes incorporating autocorrelation) in parameters often considered fixed in stock assessments such as natural mortality, future recruitment about a stock–recruitment relationship and selectivity."
* **Stock Synthesis (SS3)** - A integrative, general population dynamics modeling program used to assess the effects of fishing on population. Available at the [Stock Synthesis website](https://vlab.ncep.noaa.gov/web/stock-synthesis/home)
* **Uncertainty** - Incorporating uncertainty into an MSE procedure is extremely important. There are several potential sources of uncertainty, which we have divided as done in [Punt et al. (2016)](https://doi.org/10.1111/faf.12104) in addition to adding **observation error**. For more details, see the glossary entries on **Process Uncertainty**, **Parameter uncertainty**, **Model uncertainty**, **Assessment error**, **Implementation error**, and observation error. [Punt et al. (2016)](https://doi.org/10.1111/faf.12104) suggest that MSE should at least consider process uncertainty (particularly deviations from the stock recruitment relationship), parameter uncertainty (particularly which relates to productivity and stock size), and observation error. *Note that [Rademeyer et al. (2007)](https://doi.org/10.1093/icesjms/fsm050) divides error into estimation error, implementation error, observation error and process error, which could be used instead. These may be more natural divisions in sources of error.*